/// Batch Upload Service
/// STORY-025: Batch Data Upload
///
/// ëŒ€ëŸ‰ ë°ì´í„° ì¼ê´„ ì—…ë¡œë“œ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.
/// ë‹¤ì¤‘ í•­ëª©ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì„œë²„ì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.
library;

import 'dart:async';
import 'dart:convert';
import 'package:flutter/foundation.dart';
import '../models/sync_queue.dart';
import '../models/screening.dart';
import '../models/referral.dart';

/// ë°°ì¹˜ ì—…ë¡œë“œ ì„¤ì •
class BatchUploadConfig {
  /// ë°°ì¹˜ë‹¹ ìµœëŒ€ í•­ëª© ìˆ˜
  final int maxBatchSize;
  
  /// ìš”ì²­ ê°„ ë”œë ˆì´ (ms)
  final int requestDelayMs;
  
  /// ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
  final int maxRetries;
  
  /// ì¬ì‹œë„ ê°„ ë”œë ˆì´ (ms)
  final int retryDelayMs;
  
  /// ì••ì¶• ì‚¬ìš© ì—¬ë¶€
  final bool useCompression;
  
  /// íƒ€ì„ì•„ì›ƒ (ì´ˆ)
  final int timeoutSeconds;

  const BatchUploadConfig({
    this.maxBatchSize = 50,
    this.requestDelayMs = 100,
    this.maxRetries = 3,
    this.retryDelayMs = 1000,
    this.useCompression = true,
    this.timeoutSeconds = 30,
  });

  /// ì €ëŒ€ì—­í­ í™˜ê²½ìš© ì„¤ì •
  static const BatchUploadConfig lowBandwidth = BatchUploadConfig(
    maxBatchSize: 10,
    requestDelayMs: 500,
    maxRetries: 5,
    retryDelayMs: 2000,
    useCompression: true,
    timeoutSeconds: 60,
  );

  /// ê³ ì† ì—°ê²°ìš© ì„¤ì •
  static const BatchUploadConfig highSpeed = BatchUploadConfig(
    maxBatchSize: 100,
    requestDelayMs: 50,
    maxRetries: 2,
    retryDelayMs: 500,
    useCompression: false,
    timeoutSeconds: 15,
  );
}

/// ë°°ì¹˜ ì—…ë¡œë“œ ê²°ê³¼
class BatchUploadResult {
  final int totalItems;
  final int successCount;
  final int failedCount;
  final List<BatchError> errors;
  final Duration duration;
  final DateTime completedAt;

  const BatchUploadResult({
    required this.totalItems,
    required this.successCount,
    required this.failedCount,
    required this.errors,
    required this.duration,
    required this.completedAt,
  });

  bool get isSuccess => failedCount == 0;
  double get successRate => totalItems > 0 ? successCount / totalItems : 0;

  factory BatchUploadResult.empty() {
    return BatchUploadResult(
      totalItems: 0,
      successCount: 0,
      failedCount: 0,
      errors: [],
      duration: Duration.zero,
      completedAt: DateTime.now(),
    );
  }

  Map<String, dynamic> toMap() {
    return {
      'total_items': totalItems,
      'success_count': successCount,
      'failed_count': failedCount,
      'errors': errors.map((e) => e.toMap()).toList(),
      'duration_ms': duration.inMilliseconds,
      'completed_at': completedAt.toIso8601String(),
    };
  }
}

/// ë°°ì¹˜ ì—ëŸ¬
class BatchError {
  final String itemId;
  final String entityType;
  final String errorMessage;
  final int? errorCode;

  const BatchError({
    required this.itemId,
    required this.entityType,
    required this.errorMessage,
    this.errorCode,
  });

  Map<String, dynamic> toMap() {
    return {
      'item_id': itemId,
      'entity_type': entityType,
      'error_message': errorMessage,
      if (errorCode != null) 'error_code': errorCode,
    };
  }
}

/// ë°°ì¹˜ ì—…ë¡œë“œ ì§„í–‰ ìƒí™©
class BatchUploadProgress {
  final int currentBatch;
  final int totalBatches;
  final int itemsProcessed;
  final int totalItems;
  final String? currentStatus;

  const BatchUploadProgress({
    required this.currentBatch,
    required this.totalBatches,
    required this.itemsProcessed,
    required this.totalItems,
    this.currentStatus,
  });

  double get progress => totalItems > 0 ? itemsProcessed / totalItems : 0;
  double get batchProgress => totalBatches > 0 ? currentBatch / totalBatches : 0;
  
  String get description {
    return 'ë°°ì¹˜ $currentBatch/$totalBatches ì—…ë¡œë“œ ì¤‘ ($itemsProcessed/$totalItems í•­ëª©)';
  }
}

/// ì—…ë¡œë“œ í•­ëª©
class UploadItem {
  final String id;
  final SyncEntityType entityType;
  final SyncOperationType operation;
  final Map<String, dynamic> data;

  const UploadItem({
    required this.id,
    required this.entityType,
    required this.operation,
    required this.data,
  });

  Map<String, dynamic> toMap() {
    return {
      'id': id,
      'entity_type': entityType.name,
      'operation': operation.name,
      'data': data,
    };
  }
}

/// ë°°ì¹˜ ì—…ë¡œë“œ ì„œë¹„ìŠ¤
class BatchUploadService {
  static final BatchUploadService _instance = BatchUploadService._internal();
  factory BatchUploadService() => _instance;
  BatchUploadService._internal();

  BatchUploadConfig _config = const BatchUploadConfig();
  bool _isUploading = false;
  
  // ì§„í–‰ ìƒí™© ìŠ¤íŠ¸ë¦¼
  final _progressController = StreamController<BatchUploadProgress>.broadcast();
  Stream<BatchUploadProgress> get progressStream => _progressController.stream;

  bool get isUploading => _isUploading;

  /// ì„¤ì • ì—…ë°ì´íŠ¸
  void updateConfig(BatchUploadConfig config) {
    _config = config;
    debugPrint('âœ“ BatchUploadConfig updated: maxBatchSize=${config.maxBatchSize}');
  }

  /// ìŠ¤í¬ë¦¬ë‹ ë°ì´í„° ì¼ê´„ ì—…ë¡œë“œ
  Future<BatchUploadResult> uploadScreenings(List<Screening> screenings) async {
    final items = screenings.map((s) => UploadItem(
      id: s.id,
      entityType: SyncEntityType.screening,
      operation: SyncOperationType.create,
      data: s.toMap(),
    )).toList();

    return uploadBatch(items);
  }

  /// ì˜ë¢° ë°ì´í„° ì¼ê´„ ì—…ë¡œë“œ
  Future<BatchUploadResult> uploadReferrals(List<Referral> referrals) async {
    final items = referrals.map((r) => UploadItem(
      id: r.id,
      entityType: SyncEntityType.referral,
      operation: SyncOperationType.create,
      data: r.toMap(),
    )).toList();

    return uploadBatch(items);
  }

  /// ì¼ê´„ ì—…ë¡œë“œ ì‹¤í–‰
  Future<BatchUploadResult> uploadBatch(List<UploadItem> items) async {
    if (_isUploading) {
      debugPrint('âš ï¸ Upload already in progress');
      return BatchUploadResult.empty();
    }

    if (items.isEmpty) {
      debugPrint('âš ï¸ No items to upload');
      return BatchUploadResult.empty();
    }

    _isUploading = true;
    final startTime = DateTime.now();
    final errors = <BatchError>[];
    int successCount = 0;

    try {
      // ë°°ì¹˜ë¡œ ë¶„í• 
      final batches = _splitIntoBatches(items);
      final totalBatches = batches.length;

      debugPrint('ğŸš€ Starting batch upload: ${items.length} items in $totalBatches batches');

      for (int batchIndex = 0; batchIndex < batches.length; batchIndex++) {
        final batch = batches[batchIndex];
        
        // ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        _progressController.add(BatchUploadProgress(
          currentBatch: batchIndex + 1,
          totalBatches: totalBatches,
          itemsProcessed: successCount,
          totalItems: items.length,
          currentStatus: 'ë°°ì¹˜ ${batchIndex + 1} ì—…ë¡œë“œ ì¤‘...',
        ));

        // ë°°ì¹˜ ì—…ë¡œë“œ ì‹¤í–‰
        final batchResult = await _uploadSingleBatch(batch, batchIndex + 1);
        
        successCount += batchResult.successCount;
        errors.addAll(batchResult.errors);

        // ë°°ì¹˜ ê°„ ë”œë ˆì´
        if (batchIndex < batches.length - 1) {
          await Future.delayed(Duration(milliseconds: _config.requestDelayMs));
        }
      }

      final duration = DateTime.now().difference(startTime);
      
      debugPrint('âœ“ Batch upload complete: $successCount/${items.length} success in ${duration.inSeconds}s');

      return BatchUploadResult(
        totalItems: items.length,
        successCount: successCount,
        failedCount: errors.length,
        errors: errors,
        duration: duration,
        completedAt: DateTime.now(),
      );
    } finally {
      _isUploading = false;
    }
  }

  /// í•­ëª©ì„ ë°°ì¹˜ë¡œ ë¶„í• 
  List<List<UploadItem>> _splitIntoBatches(List<UploadItem> items) {
    final batches = <List<UploadItem>>[];
    
    for (int i = 0; i < items.length; i += _config.maxBatchSize) {
      final end = (i + _config.maxBatchSize < items.length) 
          ? i + _config.maxBatchSize 
          : items.length;
      batches.add(items.sublist(i, end));
    }
    
    return batches;
  }

  /// ë‹¨ì¼ ë°°ì¹˜ ì—…ë¡œë“œ
  Future<_BatchResult> _uploadSingleBatch(List<UploadItem> batch, int batchNumber) async {
    final errors = <BatchError>[];
    int successCount = 0;
    int retryCount = 0;

    while (retryCount < _config.maxRetries) {
      try {
        // ë°°ì¹˜ ë°ì´í„° ì¤€ë¹„
        final payload = _preparePayload(batch);
        
        // ì„œë²„ ì—…ë¡œë“œ ì‹¤í–‰ (ì‹œë®¬ë ˆì´ì…˜)
        await _performUpload(payload);
        
        successCount = batch.length;
        debugPrint('  âœ“ Batch $batchNumber: ${batch.length} items uploaded');
        break;
      } catch (e) {
        retryCount++;
        
        if (retryCount >= _config.maxRetries) {
          // ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼ - ê°œë³„ í•­ëª© ì²˜ë¦¬
          for (final item in batch) {
            errors.add(BatchError(
              itemId: item.id,
              entityType: item.entityType.name,
              errorMessage: e.toString(),
            ));
          }
          debugPrint('  âœ— Batch $batchNumber failed after $retryCount retries: $e');
        } else {
          debugPrint('  âš ï¸ Batch $batchNumber retry $retryCount: $e');
          await Future.delayed(Duration(milliseconds: _config.retryDelayMs));
        }
      }
    }

    return _BatchResult(
      successCount: successCount,
      errors: errors,
    );
  }

  /// í˜ì´ë¡œë“œ ì¤€ë¹„
  Map<String, dynamic> _preparePayload(List<UploadItem> items) {
    final payload = {
      'items': items.map((i) => i.toMap()).toList(),
      'timestamp': DateTime.now().toIso8601String(),
      'batch_id': DateTime.now().millisecondsSinceEpoch.toString(),
    };

    if (_config.useCompression) {
      // ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” gzip ì••ì¶• ì ìš©
      // í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜
      payload['compressed'] = true;
    }

    return payload;
  }

  /// ì„œë²„ ì—…ë¡œë“œ ì‹¤í–‰ (ì¶”í›„ ì‹¤ì œ API ì—°ë™)
  Future<void> _performUpload(Map<String, dynamic> payload) async {
    // TODO: ì‹¤ì œ HTTP ìš”ì²­ êµ¬í˜„
    // í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜
    await Future.delayed(Duration(milliseconds: 200));

    // ì‹œë®¬ë ˆì´ì…˜: 10% í™•ë¥ ë¡œ ì‹¤íŒ¨
    // if (Random().nextDouble() < 0.1) {
    //   throw Exception('Simulated network error');
    // }
  }

  /// ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  void dispose() {
    _progressController.close();
  }
}

/// ë‚´ë¶€ ë°°ì¹˜ ê²°ê³¼
class _BatchResult {
  final int successCount;
  final List<BatchError> errors;

  const _BatchResult({
    required this.successCount,
    required this.errors,
  });
}

/// ë°°ì¹˜ ì—…ë¡œë“œ ìœ í‹¸ë¦¬í‹°
class BatchUploadUtils {
  /// ì—”í‹°í‹° íƒ€ì…ë³„ë¡œ í•­ëª© ê·¸ë£¹í™”
  static Map<SyncEntityType, List<UploadItem>> groupByEntityType(List<UploadItem> items) {
    final grouped = <SyncEntityType, List<UploadItem>>{};
    
    for (final item in items) {
      grouped.putIfAbsent(item.entityType, () => []).add(item);
    }
    
    return grouped;
  }

  /// ìš°ì„ ìˆœìœ„ë³„ ì •ë ¬
  static List<UploadItem> sortByPriority(List<UploadItem> items) {
    // ì˜ë¢° > ìŠ¤í¬ë¦¬ë‹ > ê¸°íƒ€ ìˆœ
    final sorted = List<UploadItem>.from(items);
    sorted.sort((a, b) {
      final priorityA = _getPriority(a.entityType);
      final priorityB = _getPriority(b.entityType);
      return priorityA.compareTo(priorityB);
    });
    return sorted;
  }

  static int _getPriority(SyncEntityType type) {
    switch (type) {
      case SyncEntityType.referral:
        return 1;
      case SyncEntityType.screening:
        return 2;
      case SyncEntityType.trainingProgress:
        return 3;
      case SyncEntityType.chwProfile:
        return 4;
    }
  }

  /// í˜ì´ë¡œë“œ í¬ê¸° ì¶”ì • (bytes)
  static int estimatePayloadSize(List<UploadItem> items) {
    final json = jsonEncode(items.map((i) => i.toMap()).toList());
    return utf8.encode(json).length;
  }

  /// ì—…ë¡œë“œ ì‹œê°„ ì¶”ì • (ì´ˆ)
  static double estimateUploadTime(
    List<UploadItem> items, {
    double bandwidthKbps = 100, // ê¸°ë³¸ 100 Kbps (2G)
  }) {
    final sizeBytes = estimatePayloadSize(items);
    final sizeKb = sizeBytes / 1024;
    return sizeKb / (bandwidthKbps / 8); // Kbps to KB/s
  }
}
